{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.download_data import download_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine_df = download_data('wine-quality','winequality-white.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(white_wine_df, test_size=0.25, random_state=123)\n",
    "\n",
    "X_train = train_df.drop(columns=['quality'])\n",
    "y_train = train_df['quality']\n",
    "\n",
    "X_test = test_df.drop(columns=['quality'])\n",
    "y_test = test_df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides',\n",
    "                    'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation on different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "     \n",
    "    \"dummyregressor\": DummyRegressor(),\n",
    "    \"ridge\": Ridge(),\n",
    "    \"randomforest\": RandomForestRegressor(),\n",
    "\n",
    "}\n",
    "\n",
    "scoring={\n",
    "        \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "        \"neg_root_mean_square\": \"neg_root_mean_squared_error\",\n",
    "        \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "        \"r2\": \"r2\"\n",
    "     }\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipe = make_pipeline(preprocessor, model)\n",
    "    scores = cross_validate(pipe, X_train, y_train, return_train_score= True, scoring = scoring)\n",
    "    scores_df = pd.DataFrame(scores).mean()\n",
    "    results_dict[model_name] = scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummyregressor</th>\n",
       "      <th>ridge</th>\n",
       "      <th>randomforest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.014554</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>1.613766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.007105</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.027779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <td>-0.789925</td>\n",
       "      <td>-0.579467</td>\n",
       "      <td>-0.395085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <td>-0.789685</td>\n",
       "      <td>-0.568744</td>\n",
       "      <td>-0.055860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_root_mean_square</th>\n",
       "      <td>-0.888473</td>\n",
       "      <td>-0.761035</td>\n",
       "      <td>-0.628162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_root_mean_square</th>\n",
       "      <td>-0.888624</td>\n",
       "      <td>-0.754138</td>\n",
       "      <td>-0.236340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <td>-0.676655</td>\n",
       "      <td>-0.590999</td>\n",
       "      <td>-0.457988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <td>-0.676591</td>\n",
       "      <td>-0.587174</td>\n",
       "      <td>-0.170919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>-0.000760</td>\n",
       "      <td>0.265500</td>\n",
       "      <td>0.499623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279763</td>\n",
       "      <td>0.929264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               dummyregressor     ridge  randomforest\n",
       "fit_time                             0.014554  0.010238      1.613766\n",
       "score_time                           0.007105  0.005526      0.027779\n",
       "test_neg_mean_squared_error         -0.789925 -0.579467     -0.395085\n",
       "train_neg_mean_squared_error        -0.789685 -0.568744     -0.055860\n",
       "test_neg_root_mean_square           -0.888473 -0.761035     -0.628162\n",
       "train_neg_root_mean_square          -0.888624 -0.754138     -0.236340\n",
       "test_neg_mean_absolute_error        -0.676655 -0.590999     -0.457988\n",
       "train_neg_mean_absolute_error       -0.676591 -0.587174     -0.170919\n",
       "test_r2                             -0.000760  0.265500      0.499623\n",
       "train_r2                             0.000000  0.279763      0.929264"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose `DummyRegressor` as the baseline here. `Ridge` and `RandomForestRegressor` all preform better than the base line `DummyRegressor`. Moreover, we observe that `RandomForestRegressor` seems to be a better model by comparing `Ridge` since we got bigger negative mean squared error, bigger negative root mean squared error, bigger negative mean absolute error and bigger r2 score in the `RandomForestRegressor` model. Therefore, for predicting the test set, we will use `RandomForestRegressor` model, but we still need to investigate more in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimazation with RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_randomforest = make_pipeline(preprocessor, RandomForestRegressor(random_state=2020))\n",
    "\n",
    "param_grid = {\n",
    "    \"randomforestregressor__n_estimators\": [10, 50, 100, 150, 200, 250, 300],\n",
    "    \"randomforestregressor__max_depth\": [3,5,7, 10]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe_randomforest, \n",
    "    param_distributions=param_grid,\n",
    "    n_iter=28,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=2020\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('standardscaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['fixed '\n",
       "                                                                                'acidity',\n",
       "                                                                                'volatile '\n",
       "                                                                                'acidity',\n",
       "                                                                                'citric '\n",
       "                                                                                'acid',\n",
       "                                                                                'residual '\n",
       "                                                                                'sugar',\n",
       "                                                                                'chlorides',\n",
       "                                                                                'free '\n",
       "                                                                                'sulfur '\n",
       "                                                                                'dioxide',\n",
       "                                                                                'total '\n",
       "                                                                                'sulfur '\n",
       "                                                                                'dioxide',\n",
       "                                                                                'density',\n",
       "                                                                                'pH',\n",
       "                                                                                'sulphates',\n",
       "                                                                                'alcohol'])])),\n",
       "                                             ('randomforestregressor',\n",
       "                                              RandomForestRegressor(random_state=2020))]),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'randomforestregressor__max_depth': [3,\n",
       "                                                                             5,\n",
       "                                                                             7,\n",
       "                                                                             10],\n",
       "                                        'randomforestregressor__n_estimators': [10,\n",
       "                                                                                50,\n",
       "                                                                                100,\n",
       "                                                                                150,\n",
       "                                                                                200,\n",
       "                                                                                250,\n",
       "                                                                                300]},\n",
       "                   random_state=2020)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestregressor__n_estimators': 300,\n",
       " 'randomforestregressor__max_depth': 10}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final results by using RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search best model score: 0.43738839475956953\n",
      "Train score on the train set: 0.7260837603778569\n",
      "Test score on the test set: 0.4311472751504126\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Search best model score: \" + str(random_search.best_score_))\n",
    "print(\"Train score on the train set: \" + str(random_search.score(X_train, y_train)))\n",
    "print(\"Test score on the test set: \" + str(random_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we can see that the final test score is around 0.4311 which seems to be not reasonable here. Therefore, `RandomForestregressor` may not be a good model to use here. However, we can find other models to improve our test scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
